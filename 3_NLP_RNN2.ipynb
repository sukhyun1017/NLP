{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.NLP - RNN2",
      "provenance": [],
      "authorship_tag": "ABX9TyOXNaD8VFBI/OtJgA95Hqgm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sukhyun1017/NLP-study/blob/main/3_NLP_RNN2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "nP8t9U7Z5ZfQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''경마장에 있는 말이 뛰고 있다\\n그의 말이 법이다\\n가는 말이 고와야 오는 말이 곱다\\n'''"
      ],
      "metadata": {
        "id": "Y1gl4D5rHNJg"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "vocab_size = len(tokenizer.word_index) + 1 #padding 을 위해 +1\n",
        "print('단어 집합의 크기 : %d' % vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6ny36n9hqFi",
        "outputId": "6ca94cf6-1489-4cb5-b629-2a294f42a4ca"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합의 크기 : 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lt55T5tAhzS3",
        "outputId": "1ca4ebc3-e56b-46e0-e714-24dc2bc8c5ac"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'말이': 1, '경마장에': 2, '있는': 3, '뛰고': 4, '있다': 5, '그의': 6, '법이다': 7, '가는': 8, '고와야': 9, '오는': 10, '곱다': 11}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text.split('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64e35pGmjFOC",
        "outputId": "c92f1f76-9540-4772-d5cf-c17a255bebdf"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['경마장에 있는 말이 뛰고 있다', '그의 말이 법이다', '가는 말이 고와야 오는 말이 곱다', '']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = list()\n",
        "for line in text.split('\\n'): # 줄바꿈 문자를 기준으로 문장 토큰화\n",
        "    encoded = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(encoded)):\n",
        "        sequence = encoded[:i+1]\n",
        "        sequences.append(sequence)\n",
        "        print(sequence)\n",
        "print('학습에 사용할 샘플의 개수: %d' % len(sequences))\n",
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ip9ZwPwGhz0Y",
        "outputId": "3427f22c-3e45-4040-868c-e1f840194991"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 3]\n",
            "[2, 3, 1]\n",
            "[2, 3, 1, 4]\n",
            "[2, 3, 1, 4, 5]\n",
            "[6, 1]\n",
            "[6, 1, 7]\n",
            "[8, 1]\n",
            "[8, 1, 9]\n",
            "[8, 1, 9, 10]\n",
            "[8, 1, 9, 10, 1]\n",
            "[8, 1, 9, 10, 1, 11]\n",
            "학습에 사용할 샘플의 개수: 11\n",
            "[[2, 3], [2, 3, 1], [2, 3, 1, 4], [2, 3, 1, 4, 5], [6, 1], [6, 1, 7], [8, 1], [8, 1, 9], [8, 1, 9, 10], [8, 1, 9, 10, 1], [8, 1, 9, 10, 1, 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.texts_to_sequences([text.split('\\n')][0])[0]"
      ],
      "metadata": {
        "id": "NSDoozC6jNlG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c46c737d-18bc-4cc1-be93-2852301ab568"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 3, 1, 4, 5]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max(len(l) for l in sequences) # 모든 샘플에서 길이가 가장 긴 샘플의 길이 출력\n",
        "print('샘플의 최대 길이 : {}'.format(max_len))"
      ],
      "metadata": {
        "id": "bGO-m7TPkqXt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f0dcdfb-f31d-49a5-a009-c77778fe21b3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플의 최대 길이 : 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#paddding\n",
        "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')"
      ],
      "metadata": {
        "id": "a2hzjKCqyJrb"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GADuezxoydXm",
        "outputId": "31342a80-655e-4e7a-e880-df0ca4a72ce5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0  0  2  3]\n",
            " [ 0  0  0  2  3  1]\n",
            " [ 0  0  2  3  1  4]\n",
            " [ 0  2  3  1  4  5]\n",
            " [ 0  0  0  0  6  1]\n",
            " [ 0  0  0  6  1  7]\n",
            " [ 0  0  0  0  8  1]\n",
            " [ 0  0  0  8  1  9]\n",
            " [ 0  0  8  1  9 10]\n",
            " [ 0  8  1  9 10  1]\n",
            " [ 8  1  9 10  1 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = np.array(sequences)\n",
        "X = sequences[:,:-1]\n",
        "y = sequences[:,-1]"
      ],
      "metadata": {
        "id": "cPqvf8F3yfHb"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KWj3ZF1yrQA",
        "outputId": "81a2e1db-33a7-4a68-f74c-863c46f60b00"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0  0  2]\n",
            " [ 0  0  0  2  3]\n",
            " [ 0  0  2  3  1]\n",
            " [ 0  2  3  1  4]\n",
            " [ 0  0  0  0  6]\n",
            " [ 0  0  0  6  1]\n",
            " [ 0  0  0  0  8]\n",
            " [ 0  0  0  8  1]\n",
            " [ 0  0  8  1  9]\n",
            " [ 0  8  1  9 10]\n",
            " [ 8  1  9 10  1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = to_categorical(y, num_classes=vocab_size)"
      ],
      "metadata": {
        "id": "7vibOXRGytrv"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 설계"
      ],
      "metadata": {
        "id": "ZlABwSS6zAka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN"
      ],
      "metadata": {
        "id": "6RiN5YC3y1tQ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 10\n",
        "hidden_units = 32\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim))\n",
        "model.add(SimpleRNN(hidden_units))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X, y, epochs=200, verbose=1)"
      ],
      "metadata": {
        "id": "2BVuHE6Vy4PO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_generation(model, tokenizer, current_word, n): # 모델, 토크나이저, 현재 단어, 반복할 횟수\n",
        "    init_word = current_word\n",
        "    sentence = ''\n",
        "\n",
        "    # n번 반복\n",
        "    for _ in range(n):\n",
        "        # 현재 단어에 대한 정수 인코딩과 패딩\n",
        "        encoded = tokenizer.texts_to_sequences([current_word])[0]\n",
        "        encoded = pad_sequences([encoded], maxlen=5, padding='pre')\n",
        "        # 입력한 X(현재 단어)에 대해서 Y를 예측하고 Y(예측한 단어)를 result에 저장.\n",
        "        result = model.predict(encoded, verbose=0)\n",
        "        result = np.argmax(result, axis=1)\n",
        "\n",
        "        for word, index in tokenizer.word_index.items(): \n",
        "            # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면 break\n",
        "            if index == result:\n",
        "                break\n",
        "\n",
        "        # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
        "        current_word = current_word + ' '  + word\n",
        "\n",
        "        # 예측 단어를 문장에 저장\n",
        "        sentence = sentence + ' ' + word\n",
        "\n",
        "    sentence = init_word + sentence\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "zgT7txxLz20E"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model, tokenizer, '경마장에', 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfExOhwc0gNj",
        "outputId": "58718901-99af-4ad5-d483-c7f977871b43"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "경마장에 있는 말이 뛰고 있다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iduH2tmg0iiS",
        "outputId": "77c27414-b054-48a4-fe04-4cc755fff420"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'가는': 8,\n",
              " '경마장에': 2,\n",
              " '고와야': 9,\n",
              " '곱다': 11,\n",
              " '그의': 6,\n",
              " '뛰고': 4,\n",
              " '말이': 1,\n",
              " '법이다': 7,\n",
              " '오는': 10,\n",
              " '있는': 3,\n",
              " '있다': 5}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "- 1차원에서 axis=0 : 열\n",
        "\n",
        "- 2차원에서 axis=0 : 행, axis=1 : 열\n",
        "\n",
        "- 3차원에서 axis=0 : 깊이(depth), axis=1 : 행, axis=2: 열\n",
        "'''"
      ],
      "metadata": {
        "id": "L37L75T015f-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result =[[[3,2,6,7,8],\n",
        "         [2,3,4,5,6],\n",
        "         [2,3,4,6,7]]]\n",
        "k = np.argmax(result, axis=2)\n",
        "print(k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtK0d1pf30Xh",
        "outputId": "b38f4216-5930-4308-c7c8-f13e86035308"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "문자집합 RNN 을 시용"
      ],
      "metadata": {
        "id": "pdyOgkG54aDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import urllib.request\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 데이터 로드\n",
        "urllib.request.urlretrieve(\"http://www.gutenberg.org/files/11/11-0.txt\", filename=\"11-0.txt\")\n",
        "\n",
        "f=open('11-0.txt', 'rb') #이진 파일 읽기\n",
        "sentences = []\n",
        "for sentence in f: # 데이터로부터 한 줄씩 읽는다.\n",
        "    sentence = sentence.strip() # strip()을 통해 \\r, \\n을 제거한다.\n",
        "    sentence = sentence.lower() # 소문자화.\n",
        "    sentence = sentence.decode('ascii', 'ignore') # \\xe2\\x80\\x99 등과 같은 바이트 열 제거\n",
        "    if len(sentence) > 0:\n",
        "        sentences.append(sentence)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "5cBaOdBX336i"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaYa_u-8J7fU",
        "outputId": "e6458e87-8f5b-43a8-cadb-e2dcf5d0e47c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the project gutenberg ebook of alices adventures in wonderland, by lewis carroll',\n",
              " 'this ebook is for the use of anyone anywhere in the united states and',\n",
              " 'most other parts of the world at no cost and with almost no restrictions',\n",
              " 'whatsoever. you may copy it, give it away or re-use it under the terms',\n",
              " 'of the project gutenberg license included with this ebook or online at']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_data = ' '.join(sentences)\n",
        "print('문자열의 길이 또는 총 문자의 개수: %d' % len(total_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBJAr8mHJ80Y",
        "outputId": "a5112b25-32cb-44bc-bcdb-06943ecb7f86"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문자열의 길이 또는 총 문자의 개수: 159484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unknk= ['sdfs','sdfsdf']\n",
        "print(''.join(unknk))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bW4YchRdMnZv",
        "outputId": "cc03aad7-f6fd-4517-f440-5fe1c9bd97f9"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sdfssdfsdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(total_data[:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqV5O6ipMxaZ",
        "outputId": "4734d94c-f8ad-4143-e303-7f773093b942"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the project gutenberg ebook of alices adventures i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_vocab = sorted(list(set(total_data)))\n",
        "vocab_size = len(char_vocab)\n",
        "print ('문자 집합의 크기 : {}'.format(vocab_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F18cEonXNBoC",
        "outputId": "7f5a7e89-f7de-4718-c9b8-e917ec814710"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문자 집합의 크기 : 56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_index = dict((char, index) for index, char in enumerate(char_vocab))\n",
        "print('문자 집합 :',char_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZU-dtuxWNzYA",
        "outputId": "7c10c403-aa6e-4108-bb63-9feac84d3382"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문자 집합 : {' ': 0, '!': 1, '\"': 2, '#': 3, '$': 4, '%': 5, \"'\": 6, '(': 7, ')': 8, '*': 9, ',': 10, '-': 11, '.': 12, '/': 13, '0': 14, '1': 15, '2': 16, '3': 17, '4': 18, '5': 19, '6': 20, '7': 21, '8': 22, '9': 23, ':': 24, ';': 25, '?': 26, '[': 27, ']': 28, '_': 29, 'a': 30, 'b': 31, 'c': 32, 'd': 33, 'e': 34, 'f': 35, 'g': 36, 'h': 37, 'i': 38, 'j': 39, 'k': 40, 'l': 41, 'm': 42, 'n': 43, 'o': 44, 'p': 45, 'q': 46, 'r': 47, 's': 48, 't': 49, 'u': 50, 'v': 51, 'w': 52, 'x': 53, 'y': 54, 'z': 55}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_char = {}\n",
        "for key, value in char_to_index.items():\n",
        "    index_to_char[value] = key"
      ],
      "metadata": {
        "id": "YyTxOEUQN5yz"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 60\n",
        "\n",
        "# 문자열의 길이를 seq_length로 나누면 전처리 후 생겨날 샘플 수\n",
        "n_samples = int(np.floor((len(total_data)) / seq_length))\n",
        "print ('샘플의 수 : {}'.format(n_samples))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izDVW86PSsei",
        "outputId": "af232f0e-c7e1-4248-ef9c-3b6105a027ca"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플의 수 : 2658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = []\n",
        "train_y = []\n",
        "\n",
        "for i in range(n_samples):\n",
        "    # 0:60 -> 60:120 -> 120:180로 loop를 돌면서 문장 샘플을 1개씩 pick.\n",
        "    X_sample = total_data[i * seq_length: (i + 1) * seq_length]\n",
        "\n",
        "    # 정수 인코딩\n",
        "    X_encoded = [char_to_index[c] for c in X_sample]\n",
        "    train_X.append(X_encoded)\n",
        "\n",
        "    # 오른쪽으로 1칸 쉬프트\n",
        "    y_sample = total_data[i * seq_length + 1: (i + 1) * seq_length + 1]\n",
        "    y_encoded = [char_to_index[c] for c in y_sample]\n",
        "    train_y.append(y_encoded)"
      ],
      "metadata": {
        "id": "NdGgCJf6TPZl"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('X 데이터의 첫번째 샘플 :',train_X[0])\n",
        "print('y 데이터의 첫번째 샘플 :',train_y[0])\n",
        "print('-'*50)\n",
        "print('X 데이터의 첫번째 샘플 디코딩 :',[index_to_char[i] for i in train_X[0]])\n",
        "print('y 데이터의 첫번째 샘플 디코딩 :',[index_to_char[i] for i in train_y[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKZIuDc6dvmc",
        "outputId": "0231be16-3c00-45c4-d6f5-d6c10f978ab8"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X 데이터의 첫번째 샘플 : [49, 37, 34, 0, 45, 47, 44, 39, 34, 32, 49, 0, 36, 50, 49, 34, 43, 31, 34, 47, 36, 0, 34, 31, 44, 44, 40, 0, 44, 35, 0, 30, 41, 38, 32, 34, 48, 0, 30, 33, 51, 34, 43, 49, 50, 47, 34, 48, 0, 38, 43, 0, 52, 44, 43, 33, 34, 47, 41, 30]\n",
            "y 데이터의 첫번째 샘플 : [37, 34, 0, 45, 47, 44, 39, 34, 32, 49, 0, 36, 50, 49, 34, 43, 31, 34, 47, 36, 0, 34, 31, 44, 44, 40, 0, 44, 35, 0, 30, 41, 38, 32, 34, 48, 0, 30, 33, 51, 34, 43, 49, 50, 47, 34, 48, 0, 38, 43, 0, 52, 44, 43, 33, 34, 47, 41, 30, 43]\n",
            "--------------------------------------------------\n",
            "X 데이터의 첫번째 샘플 디코딩 : ['t', 'h', 'e', ' ', 'p', 'r', 'o', 'j', 'e', 'c', 't', ' ', 'g', 'u', 't', 'e', 'n', 'b', 'e', 'r', 'g', ' ', 'e', 'b', 'o', 'o', 'k', ' ', 'o', 'f', ' ', 'a', 'l', 'i', 'c', 'e', 's', ' ', 'a', 'd', 'v', 'e', 'n', 't', 'u', 'r', 'e', 's', ' ', 'i', 'n', ' ', 'w', 'o', 'n', 'd', 'e', 'r', 'l', 'a']\n",
            "y 데이터의 첫번째 샘플 디코딩 : ['h', 'e', ' ', 'p', 'r', 'o', 'j', 'e', 'c', 't', ' ', 'g', 'u', 't', 'e', 'n', 'b', 'e', 'r', 'g', ' ', 'e', 'b', 'o', 'o', 'k', ' ', 'o', 'f', ' ', 'a', 'l', 'i', 'c', 'e', 's', ' ', 'a', 'd', 'v', 'e', 'n', 't', 'u', 'r', 'e', 's', ' ', 'i', 'n', ' ', 'w', 'o', 'n', 'd', 'e', 'r', 'l', 'a', 'n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = to_categorical(train_X)\n",
        "train_y = to_categorical(train_y)\n",
        "print('train_X의 크기(shape) : {}'.format(train_X.shape)) # 원-핫 인코딩\n",
        "print('train_y의 크기(shape) : {}'.format(train_y.shape)) # 원-핫 인코딩\n",
        "#2658 샘플의 수 #60 sequece:샘플의 길이 #56 각 벡터의 차원"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FiMEXJYdzMJ",
        "outputId": "19b6e86b-cec3-4fe4-c559-e3274dd87f7b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_X의 크기(shape) : (2658, 60, 56)\n",
            "train_y의 크기(shape) : (2658, 60, 56)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 설계하기"
      ],
      "metadata": {
        "id": "lbozEGXzgRTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, TimeDistributed\n",
        "\n",
        "hidden_units = 256\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(hidden_units, input_shape=(None, train_X.shape[2]), return_sequences=True))\n",
        "model.add(LSTM(hidden_units, return_sequences=True))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(train_X, train_y, epochs=40, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pd-I9xP3fZlI",
        "outputId": "052faede-8497-4eef-9473-856164831261"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "84/84 - 9s - loss: 3.0778 - accuracy: 0.1792 - 9s/epoch - 104ms/step\n",
            "Epoch 2/40\n",
            "84/84 - 3s - loss: 2.7892 - accuracy: 0.2323 - 3s/epoch - 35ms/step\n",
            "Epoch 3/40\n",
            "84/84 - 3s - loss: 2.4115 - accuracy: 0.3235 - 3s/epoch - 35ms/step\n",
            "Epoch 4/40\n",
            "84/84 - 3s - loss: 2.2443 - accuracy: 0.3613 - 3s/epoch - 35ms/step\n",
            "Epoch 5/40\n",
            "84/84 - 3s - loss: 2.1298 - accuracy: 0.3904 - 3s/epoch - 35ms/step\n",
            "Epoch 6/40\n",
            "84/84 - 3s - loss: 2.0377 - accuracy: 0.4119 - 3s/epoch - 36ms/step\n",
            "Epoch 7/40\n",
            "84/84 - 3s - loss: 1.9625 - accuracy: 0.4332 - 3s/epoch - 35ms/step\n",
            "Epoch 8/40\n",
            "84/84 - 3s - loss: 1.8971 - accuracy: 0.4508 - 3s/epoch - 35ms/step\n",
            "Epoch 9/40\n",
            "84/84 - 3s - loss: 1.8378 - accuracy: 0.4675 - 3s/epoch - 36ms/step\n",
            "Epoch 10/40\n",
            "84/84 - 3s - loss: 1.7851 - accuracy: 0.4817 - 3s/epoch - 35ms/step\n",
            "Epoch 11/40\n",
            "84/84 - 3s - loss: 1.7359 - accuracy: 0.4951 - 3s/epoch - 35ms/step\n",
            "Epoch 12/40\n",
            "84/84 - 3s - loss: 1.6939 - accuracy: 0.5057 - 3s/epoch - 35ms/step\n",
            "Epoch 13/40\n",
            "84/84 - 3s - loss: 1.6536 - accuracy: 0.5162 - 3s/epoch - 35ms/step\n",
            "Epoch 14/40\n",
            "84/84 - 3s - loss: 1.6149 - accuracy: 0.5260 - 3s/epoch - 36ms/step\n",
            "Epoch 15/40\n",
            "84/84 - 3s - loss: 1.5813 - accuracy: 0.5360 - 3s/epoch - 36ms/step\n",
            "Epoch 16/40\n",
            "84/84 - 3s - loss: 1.5454 - accuracy: 0.5450 - 3s/epoch - 36ms/step\n",
            "Epoch 17/40\n",
            "84/84 - 3s - loss: 1.5129 - accuracy: 0.5535 - 3s/epoch - 35ms/step\n",
            "Epoch 18/40\n",
            "84/84 - 3s - loss: 1.4812 - accuracy: 0.5625 - 3s/epoch - 35ms/step\n",
            "Epoch 19/40\n",
            "84/84 - 3s - loss: 1.4528 - accuracy: 0.5707 - 3s/epoch - 35ms/step\n",
            "Epoch 20/40\n",
            "84/84 - 3s - loss: 1.4203 - accuracy: 0.5793 - 3s/epoch - 35ms/step\n",
            "Epoch 21/40\n",
            "84/84 - 3s - loss: 1.3893 - accuracy: 0.5884 - 3s/epoch - 36ms/step\n",
            "Epoch 22/40\n",
            "84/84 - 3s - loss: 1.3634 - accuracy: 0.5954 - 3s/epoch - 36ms/step\n",
            "Epoch 23/40\n",
            "84/84 - 3s - loss: 1.3324 - accuracy: 0.6043 - 3s/epoch - 37ms/step\n",
            "Epoch 24/40\n",
            "84/84 - 3s - loss: 1.3078 - accuracy: 0.6117 - 3s/epoch - 38ms/step\n",
            "Epoch 25/40\n",
            "84/84 - 3s - loss: 1.2782 - accuracy: 0.6194 - 3s/epoch - 36ms/step\n",
            "Epoch 26/40\n",
            "84/84 - 3s - loss: 1.2499 - accuracy: 0.6274 - 3s/epoch - 37ms/step\n",
            "Epoch 27/40\n",
            "84/84 - 3s - loss: 1.2229 - accuracy: 0.6347 - 3s/epoch - 35ms/step\n",
            "Epoch 28/40\n",
            "84/84 - 3s - loss: 1.1940 - accuracy: 0.6443 - 3s/epoch - 36ms/step\n",
            "Epoch 29/40\n",
            "84/84 - 3s - loss: 1.1669 - accuracy: 0.6513 - 3s/epoch - 36ms/step\n",
            "Epoch 30/40\n",
            "84/84 - 3s - loss: 1.1428 - accuracy: 0.6591 - 3s/epoch - 37ms/step\n",
            "Epoch 31/40\n",
            "84/84 - 3s - loss: 1.1141 - accuracy: 0.6666 - 3s/epoch - 36ms/step\n",
            "Epoch 32/40\n",
            "84/84 - 3s - loss: 1.0850 - accuracy: 0.6763 - 3s/epoch - 35ms/step\n",
            "Epoch 33/40\n",
            "84/84 - 3s - loss: 1.0556 - accuracy: 0.6852 - 3s/epoch - 36ms/step\n",
            "Epoch 34/40\n",
            "84/84 - 3s - loss: 1.0261 - accuracy: 0.6948 - 3s/epoch - 35ms/step\n",
            "Epoch 35/40\n",
            "84/84 - 3s - loss: 1.0003 - accuracy: 0.7018 - 3s/epoch - 36ms/step\n",
            "Epoch 36/40\n",
            "84/84 - 3s - loss: 0.9731 - accuracy: 0.7113 - 3s/epoch - 35ms/step\n",
            "Epoch 37/40\n",
            "84/84 - 3s - loss: 0.9523 - accuracy: 0.7156 - 3s/epoch - 35ms/step\n",
            "Epoch 38/40\n",
            "84/84 - 3s - loss: 0.9199 - accuracy: 0.7263 - 3s/epoch - 36ms/step\n",
            "Epoch 39/40\n",
            "84/84 - 3s - loss: 0.8934 - accuracy: 0.7346 - 3s/epoch - 35ms/step\n",
            "Epoch 40/40\n",
            "84/84 - 3s - loss: 0.8725 - accuracy: 0.7403 - 3s/epoch - 36ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8f2361ff50>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_generation(model, length):\n",
        "    # 문자에 대한 랜덤한 정수 생성\n",
        "    ix = [np.random.randint(vocab_size)]\n",
        "\n",
        "    # 랜덤한 정수로부터 맵핑되는 문자 생성\n",
        "    y_char = [index_to_char[ix[-1]]]\n",
        "    print(ix[0],'번 문자',y_char[-1],'로 예측을 시작!')\n",
        "\n",
        "    # (1, length, 56) 크기의 X 생성. 즉, LSTM의 입력 시퀀스 생성\n",
        "    X = np.zeros((1, length, vocab_size))\n",
        "\n",
        "    for i in range(length):\n",
        "        # X[0][i][예측한 문자의 인덱스] = 1, 즉, 예측 문자를 다음 입력 시퀀스에 추가\n",
        "        X[0][i][ix[-1]] = 1 #먼소리지\n",
        "        print(index_to_char[ix[-1]], end=\"\")\n",
        "        ix = np.argmax(model.predict(X[:, :i+1, :])[0], axis= 1)\n",
        "        y_char.append(index_to_char[ix[-1]])\n",
        "    return (''.join(y_char))\n"
      ],
      "metadata": {
        "id": "iI74MTZWpq9w"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = sentence_generation(model, 100) # 글 길이가 100\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvCIjlHipwMy",
        "outputId": "0be400b8-1fa4-4f08-86e0-d1e722ea9e60"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22 번 문자 8 로 예측을 시작!\n",
            "8 the mouse did not agree to be so in and like to day with the project gutenberg-tm electronic work 8 the mouse did not agree to be so in and like to day with the project gutenberg-tm electronic work i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.zeros((1, 10, vocab_size))\n",
        "np.argmax(model.predict(X[:, :3, :])[0], axis= 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2pnUrcpYKLv",
        "outputId": "266e6fb7-5f48-494f-b643-c5c03cf1237d"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0, 38, 38])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "다대일 구조 RNN"
      ],
      "metadata": {
        "id": "WpOF6aEeaPq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "IBqDusqqaLQB"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text = '''\n",
        "I get on with life as a programmer,\n",
        "I like to contemplate beer.\n",
        "But when I start to daydream,\n",
        "My mind turns straight to wine.\n",
        "\n",
        "Do I love wine more than beer?\n",
        "\n",
        "I like to use words about beer.\n",
        "But when I stop my talking,\n",
        "My mind turns straight to wine.\n",
        "\n",
        "I hate bugs and errors.\n",
        "But I just think back to wine,\n",
        "And I'm happy once again.\n",
        "\n",
        "I like to hang out with programming and deep learning.\n",
        "But when left alone,\n",
        "My mind turns straight to wine.\n",
        "'''"
      ],
      "metadata": {
        "id": "9GNEC91rab-D"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = raw_text.split()\n",
        "raw_text = ' '.join(tokens)\n",
        "print(raw_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjI9zuVdakq1",
        "outputId": "4a14867b-33b7-484e-ba2d-ada386091859"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I get on with life as a programmer, I like to contemplate beer. But when I start to daydream, My mind turns straight to wine. Do I love wine more than beer? I like to use words about beer. But when I stop my talking, My mind turns straight to wine. I hate bugs and errors. But I just think back to wine, And I'm happy once again. I like to hang out with programming and deep learning. But when left alone, My mind turns straight to wine.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 중복을 제거한 문자 집합 생성\n",
        "char_vocab = sorted(list(set(raw_text)))\n",
        "vocab_size = len(char_vocab)\n",
        "print('문자 집합 :',char_vocab)\n",
        "print ('문자 집합의 크기 : {}'.format(vocab_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYIX8U6Las0J",
        "outputId": "65013eb8-c7dd-43c8-f4f7-7631dd8f2f7a"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문자 집합 : [' ', \"'\", ',', '.', '?', 'A', 'B', 'D', 'I', 'M', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'y']\n",
            "문자 집합의 크기 : 33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_index = dict((char, index) for index, char in enumerate(char_vocab)) # 문자에 고유한 정수 인덱스 부여\n",
        "print(char_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BR3SSj8xa4lU",
        "outputId": "87f41afa-1bf4-45d0-c358-420d32692d23"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 0, \"'\": 1, ',': 2, '.': 3, '?': 4, 'A': 5, 'B': 6, 'D': 7, 'I': 8, 'M': 9, 'a': 10, 'b': 11, 'c': 12, 'd': 13, 'e': 14, 'f': 15, 'g': 16, 'h': 17, 'i': 18, 'j': 19, 'k': 20, 'l': 21, 'm': 22, 'n': 23, 'o': 24, 'p': 25, 'r': 26, 's': 27, 't': 28, 'u': 29, 'v': 30, 'w': 31, 'y': 32}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "length = 11\n",
        "sequences = []\n",
        "for i in range(length, len(raw_text)):\n",
        "    seq = raw_text[i-length:i] # 길이 11의 문자열을 지속적으로 만든다.\n",
        "    sequences.append(seq)\n",
        "print('총 훈련 샘플의 수: %d' % len(sequences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRiiQc2ia60g",
        "outputId": "70a3515d-7fc9-4df8-9585-f05b181bbcc1"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 훈련 샘플의 수: 426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViFp39DibcXP",
        "outputId": "97794d2e-c4f8-40f8-8c18-79d48068c42c"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I get on wi',\n",
              " ' get on wit',\n",
              " 'get on with',\n",
              " 'et on with ',\n",
              " 't on with l',\n",
              " ' on with li',\n",
              " 'on with lif',\n",
              " 'n with life',\n",
              " ' with life ',\n",
              " 'with life a']"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_sequences = []\n",
        "for sequence in sequences: # 전체 데이터에서 문장 샘플을 1개씩 꺼낸다.\n",
        "    encoded_sequence = [char_to_index[char] for char in sequence] # 문장 샘플에서 각 문자에 대해서 정수 인코딩을 수행.\n",
        "    encoded_sequences.append(encoded_sequence)"
      ],
      "metadata": {
        "id": "nbS3aEpDbsmX"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_sequences[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrCVhNw0dxYT",
        "outputId": "5dfd8494-6030-4e09-bc6d-431c69a3eef0"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[8, 0, 16, 14, 28, 0, 24, 23, 0, 31, 18],\n",
              " [0, 16, 14, 28, 0, 24, 23, 0, 31, 18, 28],\n",
              " [16, 14, 28, 0, 24, 23, 0, 31, 18, 28, 17]]"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_sequences = np.array(encoded_sequences)\n",
        "\n",
        "# 맨 마지막 위치의 문자를 분리 # input_length(길이)가 11에서 10이됨\n",
        "X_data = encoded_sequences[:,:-1]\n",
        "# 맨 마지막 위치의 문자를 저장\n",
        "y_data = encoded_sequences[:,-1]"
      ],
      "metadata": {
        "id": "iwcf62XkdoVR"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_data[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQcL1dugeiAr",
        "outputId": "f3018eda-a48c-4fb1-b5c8-b1fb96a55cb0"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 8,  0, 16, 14, 28,  0, 24, 23,  0, 31],\n",
              "       [ 0, 16, 14, 28,  0, 24, 23,  0, 31, 18],\n",
              "       [16, 14, 28,  0, 24, 23,  0, 31, 18, 28],\n",
              "       [14, 28,  0, 24, 23,  0, 31, 18, 28, 17],\n",
              "       [28,  0, 24, 23,  0, 31, 18, 28, 17,  0]])"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 원-핫 인코딩\n",
        "X_data_one_hot = [to_categorical(encoded, num_classes=vocab_size) for encoded in X_data]\n",
        "X_data_one_hot = np.array(X_data_one_hot)\n",
        "y_data_one_hot = to_categorical(y_data, num_classes=vocab_size)"
      ],
      "metadata": {
        "id": "968Q9fMreA1F"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_data_one_hot.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5I64RtFeIvI",
        "outputId": "4778dce1-6723-4291-d15d-1ba6a0368086"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(426, 10, 33)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_data_one_hot[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1pMDko7eq9f",
        "outputId": "855ce379-63a9-4837-8d8e-b9c533ef509d"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "        0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "        0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "hidden_units = 64\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(hidden_units, input_shape=(X_data_one_hot.shape[1], X_data_one_hot.shape[2])))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_data_one_hot, y_data_one_hot, epochs=100, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZEuHWG2f-ym",
        "outputId": "6ae484f4-2b49-429b-8abf-1d2180631e50"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 - 0s - loss: 0.4354 - accuracy: 0.9343 - 76ms/epoch - 5ms/step\n",
            "Epoch 88/100\n",
            "14/14 - 0s - loss: 0.4228 - accuracy: 0.9413 - 72ms/epoch - 5ms/step\n",
            "Epoch 89/100\n",
            "14/14 - 0s - loss: 0.4095 - accuracy: 0.9437 - 84ms/epoch - 6ms/step\n",
            "Epoch 90/100\n",
            "14/14 - 0s - loss: 0.3984 - accuracy: 0.9460 - 77ms/epoch - 5ms/step\n",
            "Epoch 91/100\n",
            "14/14 - 0s - loss: 0.3801 - accuracy: 0.9484 - 72ms/epoch - 5ms/step\n",
            "Epoch 92/100\n",
            "14/14 - 0s - loss: 0.3686 - accuracy: 0.9531 - 72ms/epoch - 5ms/step\n",
            "Epoch 93/100\n",
            "14/14 - 0s - loss: 0.3666 - accuracy: 0.9460 - 73ms/epoch - 5ms/step\n",
            "Epoch 94/100\n",
            "14/14 - 0s - loss: 0.3643 - accuracy: 0.9484 - 78ms/epoch - 6ms/step\n",
            "Epoch 95/100\n",
            "14/14 - 0s - loss: 0.3526 - accuracy: 0.9437 - 72ms/epoch - 5ms/step\n",
            "Epoch 96/100\n",
            "14/14 - 0s - loss: 0.3367 - accuracy: 0.9484 - 70ms/epoch - 5ms/step\n",
            "Epoch 97/100\n",
            "14/14 - 0s - loss: 0.3241 - accuracy: 0.9531 - 71ms/epoch - 5ms/step\n",
            "Epoch 98/100\n",
            "14/14 - 0s - loss: 0.3211 - accuracy: 0.9554 - 71ms/epoch - 5ms/step\n",
            "Epoch 99/100\n",
            "14/14 - 0s - loss: 0.3036 - accuracy: 0.9601 - 80ms/epoch - 6ms/step\n",
            "Epoch 100/100\n",
            "14/14 - 0s - loss: 0.2910 - accuracy: 0.9648 - 77ms/epoch - 5ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8f1e497b50>"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_generation(model, char_to_index, seq_length, seed_text, n):\n",
        "\n",
        "    # 초기 시퀀스\n",
        "    init_text = seed_text\n",
        "    sentence = ''\n",
        "\n",
        "    # 다음 문자 예측은 총 n번만 반복.\n",
        "    for _ in range(n):\n",
        "        encoded = [char_to_index[char] for char in seed_text] # 현재 시퀀스에 대한 정수 인코딩\n",
        "        encoded = pad_sequences([encoded], maxlen=seq_length, padding='pre') # 데이터에 대한 패딩\n",
        "        encoded = to_categorical(encoded, num_classes=len(char_to_index)) #원핫인코딩\n",
        "\n",
        "        # 입력한 X(현재 시퀀스)에 대해서 y를 예측하고 y(예측한 문자)를 result에 저장.\n",
        "        result = model.predict(encoded, verbose=0)\n",
        "        result = np.argmax(result, axis=1)\n",
        "\n",
        "        for char, index in char_to_index.items(): #예측에 해당하는 char 찾기\n",
        "            if index == result:\n",
        "                break\n",
        "\n",
        "        # 현재 시퀀스 + 예측 문자를 현재 시퀀스로 변경\n",
        "        seed_text = seed_text + char\n",
        "\n",
        "        # 예측 문자를 문장에 저장\n",
        "        sentence = sentence + char\n",
        "\n",
        "    # n번의 다음 문자 예측이 끝나면 최종 완성된 문장을 리턴.\n",
        "    sentence = init_text + sentence\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "vLirYxsKgsFF"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model, char_to_index, 10, 'i get a ', 80))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8g7FSqNIhHf1",
        "outputId": "7ac15d22-31f7-4582-ff60-7841eb71de63"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i get a in  o tii ttroeee bt wien  y tggn tttttiheee My an nniuuutsshss faaa  ogr Mydt t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "H1l9771uhmKf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}